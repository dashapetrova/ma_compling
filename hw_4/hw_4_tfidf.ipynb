{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_4_tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik9YupN2IIBY",
        "outputId": "1bea1f42-7e55-4ab6-c9a6-035e11f74c28"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive') #, force_remount=True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRQJ2EWOIRyF"
      },
      "source": [
        "import os\r\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fVTAp4nLAJv"
      },
      "source": [
        "!pip install pymorphy2\r\n",
        "!pip install pymystem3==0.1.10\r\n",
        "!pip install rusenttokenize\r\n",
        "!pip install razdel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mNtuqFILCbr",
        "outputId": "ccf6f9f0-f9cb-4655-fd81-3d04d1516520"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma6MVr4GLLG0"
      },
      "source": [
        "import os, re\r\n",
        "from string import punctuation\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "from collections import Counter, defaultdict\r\n",
        "from pprint import pprint\r\n",
        "from nltk import sent_tokenize\r\n",
        "punctuation += \"«»—…“”\"\r\n",
        "punct = set(punctuation)\r\n",
        "from sklearn.metrics import classification_report, accuracy_score\r\n",
        "from string import punctuation\r\n",
        "from razdel import sentenize\r\n",
        "from razdel import tokenize as razdel_tokenize\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "import math\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "def normalize(text):\r\n",
        "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\r\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\r\n",
        "    return normalized_text"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPEsNPq3WFDK"
      },
      "source": [
        "**Задание 1.**\r\n",
        "\r\n",
        "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \r\n",
        "Можно считать в google sheets, екселе, питоне или на листочке. Сделайте скрин получившейся таблицы и загрузите картинку на гитхаб, вставьте ссылку в поле ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtOEDfkNJVDm"
      },
      "source": [
        "texts = ['я и ты', 'ты и я', 'я, я и только я', 'только не я', 'он']"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaV-3xSTJ-hh",
        "outputId": "1b395c60-6231-47ea-8c60-14b3f52f99dc"
      },
      "source": [
        "def build_terms(corpus):\r\n",
        "    terms = {}\r\n",
        "    for doc in corpus:\r\n",
        "        for word in normalize(doc):\r\n",
        "            if word not in terms:\r\n",
        "              terms[word] = 1\r\n",
        "            else:\r\n",
        "              terms[word] += 1\r\n",
        "    return terms\r\n",
        "\r\n",
        "terms = build_terms(texts)\r\n",
        "terms\r\n",
        "vocab = list(terms.keys())\r\n",
        "vocab"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['я', 'и', 'ты', 'только', 'не', 'он']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeFlaGLCMQyo"
      },
      "source": [
        "def tf(document, terms):\r\n",
        "    words = normalize(document)\r\n",
        "    total_words = len(words)\r\n",
        "    doc_counter = Counter(words)\r\n",
        "    for word in doc_counter:\r\n",
        "      doc_counter[word] /= total_words\r\n",
        "    tfs = [0 for _ in range(len(terms))]\r\n",
        "    for i in range(len(terms)):\r\n",
        "      tfs[i] = doc_counter[terms[i]]\r\n",
        "    return tfs\r\n",
        "\r\n",
        "def count_docs_with_word(word, docs):\r\n",
        "    counter = 0\r\n",
        "    for doc in docs:\r\n",
        "        if word in doc:\r\n",
        "            counter += 1\r\n",
        "    return counter\r\n",
        "\r\n",
        "def idf(documents, terms):\r\n",
        "    idfs = [0 for _ in range(len(terms))]\r\n",
        "    total_docs = len(documents)\r\n",
        "    for i in range(len(terms)):\r\n",
        "      docs_with_word = count_docs_with_word(terms[i], documents)\r\n",
        "      idf = 1 + math.log((total_docs+1) / (docs_with_word+1))\r\n",
        "      idfs[i] = idf\r\n",
        "    return idfs\r\n",
        "\r\n",
        "def td_idf(tf, idf, terms):\r\n",
        "    return [tf[i] * idf[i] for i in range(len(terms))]\r\n",
        "\r\n",
        "def build_tfidf(corpus, document, terms):\r\n",
        "    doc_tf = tf(document, terms)\r\n",
        "    doc_idf = idf(corpus, terms)\r\n",
        "    return td_idf(doc_tf, doc_idf, terms)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mE0T_w5NGre"
      },
      "source": [
        "tf_idf_total = []\r\n",
        "for document in texts:\r\n",
        "  tf_idf_total.append(build_tfidf(texts, document, vocab))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BsqPhYSESY0w",
        "outputId": "de6333c2-3016-4d74-b34b-060a6949551d"
      },
      "source": [
        "import pandas as pd\r\n",
        "frame = pd.DataFrame(tf_idf_total, columns=terms, index=texts)\r\n",
        "frame"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>я</th>\n",
              "      <th>и</th>\n",
              "      <th>ты</th>\n",
              "      <th>только</th>\n",
              "      <th>не</th>\n",
              "      <th>он</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>я и ты</th>\n",
              "      <td>0.394107</td>\n",
              "      <td>0.468488</td>\n",
              "      <td>0.564382</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ты и я</th>\n",
              "      <td>0.394107</td>\n",
              "      <td>0.468488</td>\n",
              "      <td>0.564382</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>я, я и только я</th>\n",
              "      <td>0.709393</td>\n",
              "      <td>0.281093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>только не я</th>\n",
              "      <td>0.394107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.564382</td>\n",
              "      <td>0.699537</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>он</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.098612</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        я         и        ты    только        не        он\n",
              "я и ты           0.394107  0.468488  0.564382  0.000000  0.000000  0.000000\n",
              "ты и я           0.394107  0.468488  0.564382  0.000000  0.000000  0.000000\n",
              "я, я и только я  0.709393  0.281093  0.000000  0.338629  0.000000  0.000000\n",
              "только не я      0.394107  0.000000  0.000000  0.564382  0.699537  0.000000\n",
              "он               0.000000  0.000000  0.000000  0.000000  0.000000  2.098612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt8zuE5pfaty"
      },
      "source": [
        "**Задание 2.**\r\n",
        "\r\n",
        "а) Посчитайте близость между 3 и 12666 текстами в датасете (labeled.csv из семинара) \r\n",
        "\r\n",
        "б) найдите 3 самых близких текста к тексту номер 43; выведите сами тексты и значения близостей, а не только индексы этих текстов. \r\n",
        "\r\n",
        "Векторизовать можно любым способом, но постарайтесь, чтобы 1 и 0 не получались в близостях.\r\n",
        "Результат запишите в тетрадке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njnL578Nf1fF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report, accuracy_score\r\n",
        "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IGldMrmhT25M",
        "outputId": "e535b8a7-345c-4e0c-e7ba-3c1faed95591"
      },
      "source": [
        "df = pd.read_csv('labeled.csv')\r\n",
        "df.head()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                          Собаке - собачья смерть\\n    1.0\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpTYh0eZgQN9"
      },
      "source": [
        "texts = df.comment\r\n",
        "vectorizer = TfidfVectorizer()\r\n",
        "X = vectorizer.fit_transform(texts)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6csNcIkBd4"
      },
      "source": [
        "а) Посчитайте близость между 3 и 12666 текстами в датасете (labeled.csv из семинара)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVpVjMj-gt6I",
        "outputId": "718ccff3-af49-4e04-80be-9a76ccd8eba4"
      },
      "source": [
        "print(texts[3])\r\n",
        "print(texts[12666])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
            "\n",
            "Это не параноик, это дебил\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da7Kocgljbbm",
        "outputId": "a5aa6759-87cb-4867-9e89-9517b0f58034"
      },
      "source": [
        "cosine_similarity(X[3], X[12666])"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.27330886]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7jgK4cckF1n"
      },
      "source": [
        "б) найдите 3 самых близких текста к тексту номер 43; выведите сами тексты и значения близостей, а не только индексы этих текстов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9V8myeJjuP-"
      },
      "source": [
        "#или argsort()\r\n",
        "sims = []\r\n",
        "for i in range(len(texts)):\r\n",
        "  cossim = cosine_similarity(X[43], X[i])\r\n",
        "  sims.append([i, cossim])"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWibO67slGz3",
        "outputId": "a4742142-259c-42c0-d4d3-b8a78a7dd7fe"
      },
      "source": [
        "sorted(sims, key = lambda x: x[1], reverse=True)[:4]"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[43, array([[1.]])],\n",
              " [1986, array([[0.16043982]])],\n",
              " [1957, array([[0.11789149]])],\n",
              " [6259, array([[0.11409081]])]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qviiEmIFkTnT",
        "outputId": "9860f53c-5900-4a46-d527-e66b1fd6f241"
      },
      "source": [
        "for i in sorted(sims, key = lambda x: x[1], reverse=True)[:4]:\r\n",
        "  print(i[0], texts[i[0]])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43 Люди зажрались и охуели если по мнению этих игроков андромеда лучше Антема. Хотя че там с багаутом76 сравнивают вон... Вот оно че оказывается, игроки просто охуели, ну ок. Вот долбанные пидерасы, не хотят покупать такую отличную игру, а еще смеют ругать такой божественный геймплей. Баги, хуевый геймплей поправят, а контент, ну его запилят, через год другой, причем бесплатно! Ага. Стоит лишь потерпеть!\n",
            "\n",
            "1986 НУ И КАКАЯ МРАЗЬ КИДАЕТ ССЫЛКИ? ОХУЕЛИ ТАМ В КРАЙ УЖЕ?\n",
            "\n",
            "1957 Че за бригада и че за махоун? Из полицейской академии?\n",
            "6259 Герка ебет только даунов которые игрли а него. Ибо и геймплей и сюжетто кусок говна.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhA6k7c8l7ZQ"
      },
      "source": [
        "**Задание 3.**\r\n",
        "\r\n",
        "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из 2ch_corpus.txt (второй семинар) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?\r\n",
        "*Можете предсказывать не все данные, но не менее 2500.\r\n",
        "\r\n",
        "Требования к классификаторам:\r\n",
        "\r\n",
        "а) один должен использовать CountVectorizer, другой TfidfVectorizer\r\n",
        "\r\n",
        "б) у векторазера должны быть вручную заданы как минимум 5 параметров\r\n",
        "\r\n",
        "в) у классификатора должно быть задано вручную как минимум 2 параметра\r\n",
        "\r\n",
        "г)  f1 мера каждого из классификаторов должна быть минимум 0.75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTmWdWhAlZoT"
      },
      "source": [
        "vect_1 = CountVectorizer(min_df=2, max_df=0.9, stop_words=stopwords.words(\"russian\"), binary='bool', lowercase='bool')\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.comment, df.toxic, test_size=0.1, random_state=42)\r\n",
        "X_train = vect_1.fit_transform(X_train)\r\n",
        "X_test = vect_1.transform(X_test)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54K3e5j3sY2X",
        "outputId": "7ecda483-7a91-479e-dc26-c7d6d1a29934"
      },
      "source": [
        "clf = LogisticRegression(C=0.5, class_weight='balanced', solver='saga', max_iter=500)\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "preds = clf.predict(X_test)\r\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.87      0.88       971\n",
            "         1.0       0.75      0.79      0.77       471\n",
            "\n",
            "    accuracy                           0.84      1442\n",
            "   macro avg       0.82      0.83      0.83      1442\n",
            "weighted avg       0.85      0.84      0.85      1442\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5A5IQr-wZLV"
      },
      "source": [
        "vect_2 = TfidfVectorizer(min_df=2, max_df=0.9, stop_words=stopwords.words(\"russian\"), binary='bool', lowercase='bool')\r\n",
        "\r\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df.comment, df.toxic, test_size=0.1, random_state=42)\r\n",
        "X_train_2 = vect_2.fit_transform(X_train_2)\r\n",
        "X_test_2 = vect_2.transform(X_test_2)"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQD_tTPa1utE",
        "outputId": "47c2b50f-b361-4825-c49f-f935ad330a4c"
      },
      "source": [
        "clf_2 = MultinomialNB(alpha=0.5, fit_prior='bool', class_prior=[1,1])\r\n",
        "clf_2.fit(X_train_2, y_train_2)\r\n",
        "preds_2 = clf_2.predict(X_test_2)\r\n",
        "print(classification_report(y_test_2, preds_2))"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.93      0.90       971\n",
            "         1.0       0.83      0.75      0.79       471\n",
            "\n",
            "    accuracy                           0.87      1442\n",
            "   macro avg       0.86      0.84      0.85      1442\n",
            "weighted avg       0.87      0.87      0.87      1442\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeDB8rIL16IN"
      },
      "source": [
        "dvach = open('2ch_corpus.txt').readlines()[:3000]"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNjagWY93z3k"
      },
      "source": [
        "def get_probs(texts, vect, model):\r\n",
        "  X_test = vect.transform(texts)\r\n",
        "  probs = model.predict_proba(X_test)\r\n",
        "  top10 = probs[:,1].argsort()[::-1][:10]\r\n",
        "  top10_probs = probs[top10, 1]\r\n",
        "\r\n",
        "  return top10, top10_probs"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozkIX0jp4B7x"
      },
      "source": [
        "#топ для первой модели\r\n",
        "top10_1, probs_1 = get_probs(dvach, vect_1, clf)"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O7eOADB7dBp",
        "outputId": "440b8dec-3819-403a-edfc-20f340c9a7d5"
      },
      "source": [
        "for i in range(10):\r\n",
        "  print(probs_1[i])\r\n",
        "  print(top10_1[i], dvach[top10_1[i]], '\\n')"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999638953752288\n",
            "256  >Scala, Clojure, Erlang, Elixir, Common Lisp, Haskell, Ocaml, F#, Elm, Swift, Go, Rust, D, Nim, Scheme, SmalltalkМолодец, перечислил сложные для старта языки + на которых вакансий хуй хуй да нихуя. Сам-то с какого языка начинал? И наверное в гарварде и mit дауны сидят и учат людей сям и питону, сука на дваче, что не доска, так куча нитаких, как все даунов на хайпе, которые толкают свое говно. Нахуй иди.\n",
            " \n",
            "\n",
            "0.9999514029087191\n",
            "2810  - Что можете сказать о стиле Тарантиныча?- Кого блять?- Квентина Тарантино.- Так и говори, блять.- Почему его героев, говорящих обо всём и ни о чём, так приятно слушать?- Потому что диалоги остроумные. Из двух слов. Умные. И острые. - Как лист салата?- Что \"как лист салата\"?- Умные.- Что за хуйню ты сейчас несешь?- Мы же сейчас о тарантиновских диалогах с тобой разговариваем?- Да, блять, о них мы и разговариваем. Ты кокаином обнюханный что ли я не пойму?- При чем здесь кокаин? Его диалоги без штампов, без стереотипов, и точно бьющие в суть. Пусть это и суть гамбургера. - Какого, мать твою, гамбургера? Ты еще скажи, что они, блять, свежие как лист салата. Гавно для наркоманов - твоё тарантино. Первые два фильма нормальные. Бешенные псы и Криминальное чтиво..- И чего же блять нормального в Криминальном чтиве? Я, если хочешь знать, героин попробовал из-за него.- И что, жалеешь?- Нет.- Пидора ответ.- Лол блять)- Ты что, на дваче сидишь.- Нет- Пидора ответ- Лол блять\n",
            " \n",
            "\n",
            "0.999827490329705\n",
            "645  Ёбаные советские названия блять. КРУЖКИ блять. Всегда ненавидел. Блять. Почему бы не сказать КЛУБ ПО ИНТЕРЕСАМ, как у япошек, нет блять, будем гуманитарную хуйню, сравнения блять, типа В КРУГ СОБРАЛИСЬ, ахахахаха кружок ахахахахаха))))) пиздец блять. Может при Сталине это звучало, но уже при Горбачёве это просто бесило, а сейчас это выглядит вообще как атавизм. Или ещё ебанутое слово СЛЁТ блять. Сука, СЛЁТ, почему слёт, а не съезд? Типа съезд - это для КПСС, не доросли ещё? Или типа в Совке так всё пиздато, что даже у школия есть своё самолёт? СЛЁТ сука, мы что, блять, стрижи? Или это какая-то аллегория на ёбаных ОРЛЯТ? Вот тоже заебучее сравнение, всегда бесило, ОРЯЛА УЧАТСЯ ЛЕТАТЬ, блять, да мне похуй на каких-то куриц, орлят, блять, голубей, петухов, учатся они летать блять, а страусы вон не учатся, мне-то что до ваших сраных ОРЛЯТ, пел всегда КОЛЗЛЯТ, да-да, школие, этот прикол существовал ещё до Задорнова и прочих клованов - в совковых песнях заменять \"орёл\" на \"козёл\". Ну до чего же сука поганая страна была, хорошо, что развалилась нахуй!\n",
            " \n",
            "\n",
            "0.9990729031463833\n",
            "456   мамка твоя мне заработала своей пиздой вонючей тварь вонючая, мразь поганая, гандон, говно, пидрила, ану иди сюда\n",
            " \n",
            "\n",
            "0.9989464644412578\n",
            "1674  Как олдфаг 29лвл, заставший конец двача, прошедший весь педальчан, и вкусивший сполна абучана, могу заверить: раньше аудиория была другой. Особенно круто было на дваче и раннем педальчане, ибо преобладала студентота преимущественно из технарей, гики, задроты, анимешники, поехавшие, и прочие интересные личности. Конечно, было дохера тредов про \"двач я посрал\", или тупые перефорсы с упячки, форчана, да даже с удаффа залетали и срали. Но это было иначе, чувствовалось, что говно, которое ты кушал в б, оно до переваривания было изысканными трюфелями, а не как сейчас, словно дошик запитый балтикой переварили и высрали. Ну или более точный пример: представь, что препод не пришел на пару, и вам предстоит почти час сидеть страдать хуйней. Так вот. 2ch. ru - это куражащиеся студенты бауманки. А харкач - это куражащиеся ПТУ-шники. Я уж не говорю, как же пиздат был вконтакт в 2007, когда там сидели онли всякие задроты, и где тян было найти, как на аиб, нечто удивительное. Как старательно люди тогда подходили к созданию сообществ, словно к маленькому уютному кружку по интересам. А сейчас поглядите на этот пиздец. Уже зашквар там сидеть. Впрочем, тут тоже зашквар уже сидеть, просто ты не понимаешь этого, как не понимает 16-летняя девочка просиживающая часами в соцсетях, то нынешний вконтакт для даунов.\n",
            " \n",
            "\n",
            "0.9986363599956793\n",
            "2467  Иди нахуй дурачек ебаный пидорас ну чтоьты за скотина ебаная оп выше написал что нашел ее а теперь иди нахкй\n",
            " \n",
            "\n",
            "0.9968863675710578\n",
            "943  Пиздец я просто с вас в ахуе, столько постов ни о чем. Двачеры действительно настолько тупые? Ответ блядь в условиях самой задачи прямым текстом написан, мозг и глаза включите, хоть на пару секунд.\n",
            " \n",
            "\n",
            "0.9967211374777034\n",
            "2924  >Сначала, если ещё не читал, почитай русскую классику типа Достоевского, Чехова, Пушкина. >Потом советскую литературу Стругацких там, ещё кого-то. Че несешь-то?Бля, не слушай его. Я читал и Достоевского, и Чехова, и Пушкина. Даже Стругацких читал. Перечитал уйму всякого говна, даже Улисса за каким-то хуем прочел. И вот что я тебе скажу - чтение не имеет никакого отношения к писательству. И сколько бы ты книг ни прочел, это не даст тебе ничего, кроме мнээээ скилла быстрочтения. Конечно, читать стоит, если тебе нравится эта хуйня. Но только ради этого, а не какого-то сомнительного соображения, что это научит тебя писать. Если хочешься научиться писать - садись и пиши.\n",
            " \n",
            "\n",
            "0.9967159728494157\n",
            "2016  А теперь почитайте что пишут всякие пезды и охуейте такой секси мм Пиздец. Какая-то марамойка в своих мечтах представляет что он увидит её камент, бросит свою пизду, заберет шлюху из Рахи и будет пялить. А она ему борщи и личиноккоторых он ненавидит будет рожать.\n",
            " \n",
            "\n",
            "0.9966777975198423\n",
            "2260  Не ты ли в мотаче про трек-сессии рассказывал?Ну и потом, как бы то ни было, нахуй тебе всралась жена, которой на тебя похуй. Ей на тебя похуй, понимаешь?\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra7NUY8H70gS"
      },
      "source": [
        "#топ для второй модели\r\n",
        "top10_2, probs_2 = get_probs(dvach, vect_2, clf_2)"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFoFp_Jb8Z-Y",
        "outputId": "414c68e4-b34b-454b-a78b-06a2e7182774"
      },
      "source": [
        "for i in range(10):\r\n",
        "  print(probs_2[i])\r\n",
        "  print(top10_2[i], dvach[top10_2[i]], '\\n')"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9955543303551457\n",
            "456   мамка твоя мне заработала своей пиздой вонючей тварь вонючая, мразь поганая, гандон, говно, пидрила, ану иди сюда\n",
            " \n",
            "\n",
            "0.9946419106455782\n",
            "2467  Иди нахуй дурачек ебаный пидорас ну чтоьты за скотина ебаная оп выше написал что нашел ее а теперь иди нахкй\n",
            " \n",
            "\n",
            "0.9925055052406684\n",
            "1372  Боже, ебаные нытики. Да не сдохнешь ты, мразь. Не ной.\n",
            " \n",
            "\n",
            "0.9858169539344932\n",
            "523  Где-то в этой пасте шлюха пиздит.\n",
            " \n",
            "\n",
            "0.9853922197713505\n",
            "2062  Фу блядь нахуй всратый.\n",
            " \n",
            "\n",
            "0.9850055463751813\n",
            "1141  Ишак ебаный, какая в пизду смекта, иди бабку свою лечи, и смотри как лечися острый панкриотит (хирург-кун)\n",
            " \n",
            "\n",
            "0.9849170754518075\n",
            "1279  Вызывай, подохнешь же, сука.\n",
            " \n",
            "\n",
            "0.9845573582923393\n",
            "1607  Кукарекает твой дружок-пидор, ну и ты вместе с ним. Слизываешь поди малафью с его очка сидишь, распизделся тута.\n",
            " \n",
            "\n",
            "0.9839760537467467\n",
            "725  Нахуй съеби, хуесос /po/рашный.\n",
            " \n",
            "\n",
            "0.9839006553295898\n",
            "979  Сука, этот тред - просто кладезь лулзов!\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqDGnPmV95H9"
      },
      "source": [
        "В получившихся топах есть общие тексты: первые два текста во 2-ом топе встречаются также и в 1-ом топе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx_xOR-i8luY",
        "outputId": "86c3640f-d47d-4149-ff52-ebc330619928"
      },
      "source": [
        "c = set(top10_1).intersection(set(top10_2))\r\n",
        "print(c)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{456, 2467}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5w3gdbD-brs"
      },
      "source": [
        "Все тексты в обоих топах токсичные. Можно отметить, что в первом топе тексты длинее, чем во втором, и, есть ощущение, что во втором топе тексты более токсичные (особенно если учесть, что в текстах из первого топа присутствуют какие-то дополнительные мысли и рассуждения, а во втором топе много просто ругани)"
      ]
    }
  ]
}
